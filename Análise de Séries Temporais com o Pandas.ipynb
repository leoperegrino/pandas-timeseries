{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "\n",
    "O problema consiste na validação de um log de dados ambientais de uma estação situada em Petrolina. Como os dados correspondem a mais de 10 anos, uma simples planilha não seria eficiente (O excel suporta apenas ~1Mi de linhas). \n",
    "\n",
    "Foi selecionada a linguagem python, onde podemos usar a biblioteca pandas para análise de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a biblioteca com prefixo pd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumindo que estamos no diretório do log, podemos ler o csv com a função `pd.read_csv()`. Atenção para não rodar a leitura múltiplas vezes, visto que o arquivo é grande e será carregado em memória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv('Petrolina.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O objeto criado é um dataframe, semelhante a uma planilha.\n",
    "type(csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizando a estrutura dos dados\n",
    "\n",
    "a biblioteca `pandas` é bastante versátil, permitindo rápidas análises. \n",
    "Podemos ver _head_ e _tail_ do _dataframe_ apenas lendo o objeto. \n",
    "Isso já nos permite entender com o que estamos lidando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'O log possui {csv.shape[0]:,} linhas e {csv.shape[1]:,} colunas')\n",
    "\n",
    "csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "já podemos ver que colunas como **GHI, DNI** e **DHI** possuem valores negativos, o que é fisicamente impossível. Provavelmente o datalogger capturou valores noturnos.\n",
    "\n",
    "Outro problema é o formato da coluna Date que está como _string_. Convertê-la para objeto _datetime_ facilita muito durante análises de séries temporais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(csv['Date'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminar o formato da coluna previamente aumenta massivamente\n",
    "# o tempo de processamento, não fazer é uma má prática\n",
    "\n",
    "csv['Date'] = pd.to_datetime(csv['Date'], format=\"%d-%b-%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(csv['Date'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra melhoria em séries temporais é [usar um índice de datas](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#indexing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.set_index('Date', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agora não temos mais o índice numérico\n",
    "csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extremos\n",
    "ver os extremos dos dados pode ajudar em reconhecer _outliers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.nlargest(10, 'GHI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.nsmallest(10, 'GHI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caracterização\n",
    "\n",
    "Por padrão, tem-se o seguinte modelo para avaliar os dados ruins de nosso log:\n",
    "\n",
    "|#|flag|significado|exemplo|\n",
    "|:---|:---|:---|---:|\n",
    "|1|bom| foi aprovado em todos os testes |ideal|\n",
    "|2|suspeito| teste não permite concluir se é correto ou é um outlier||\n",
    "|3|anômalo| não será avaliado em nenhum dos testes posteriores||\n",
    "|4|previamente anômalo| teste anterior caracterizou-o como anômalo||\n",
    "|5|dado não testado| não será avaliado em qualquer teste do procedimento.| dados noturnos|\n",
    "|6|dado não disponível| não foi registrado pelo sistema de aquisição de dados| NaN|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes de Lacunas\n",
    "\n",
    "- [ ] Descontinuidade\n",
    "- [ ] Missing data\n",
    "- [ ] Duplicidade de datas\n",
    "- [ ] Lacunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetar o índice para poder diferenciar os timestamps\n",
    "# e depois agrupar-los\n",
    "csv.reset_index().diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.reset_index().diff().groupby('Date').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como em toda série temporal só temos intervalos de 1 minuto, conclui-se que não há descontinuidadem duplicidade ou lacunas.\n",
    "- [x] Descontinuidade\n",
    "- [ ] Missing data\n",
    "- [x] Duplicidade de datas\n",
    "- [x] Lacunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtdNan = csv['GHI'].isna().sum()\n",
    "\n",
    "print(f'são {qtdNan:,} dados GHI ausentes que representam',\n",
    "      f'cerca de {qtdNan/len(csv)*100:.3}% do total')\n",
    "\n",
    "csv[csv['GHI'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv['NaN'] = csv['GHI'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Descontinuidade\n",
    "- [x] Missing data\n",
    "- [x] Duplicidade de datas\n",
    "- [x] Lacunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negativos = csv['GHI'] < 0\n",
    "qtdNegativos = csv[negativos]['GHI'].count()\n",
    "\n",
    "print(f'são {qtdNegativos:,} dados GHI negativos que representam',\n",
    "      f'cerca de {qtdNegativos/len(csv)*100:.4}% do total')\n",
    "\n",
    "csv[negativos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Ao todo, já podemos ver a presença de {qtdNan + qtdNegativos:,}\",\n",
    "      \" dados sem utilidade na avaliação do recurso solar,\",  \n",
    "      f\"representando {(qtdNan + qtdNegativos) * 100 / csv.shape[0]:.3}% do total.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes Locais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import solar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a análise de _Tracker off_ é necessário $\\cos\\theta$. Entretanto, uma primeira análise pode ser feita desconsiderando as seguintes situações:\n",
    "\n",
    "$\\frac{I_d}{I_g} > 1$\n",
    "ou \n",
    "$\\frac{I_{bn}}{I_g} > 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv['Tracker off'] = (csv['DHI'])/csv['GHI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpando e visualizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar uma coluna com o ano de cada timestamp\n",
    "# para poder ver o boxplot de cada ano\n",
    "\n",
    "csv['ano'] = csv.index.year\n",
    "csv.boxplot(by='ano', column='GHI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apesar de ser possível visualizar, os dados estão mal representados por causa de _bad data_. Deve-se avaliar depois de limpar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limpar os valores negativos\n",
    "\n",
    "csv.drop(csv[csv['GHI'] < 0].index, inplace=True)\n",
    "\n",
    "# limpar NaN's\n",
    "\n",
    "csv.dropna(subset=['GHI'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# novamente\n",
    "csv.boxplot(by='ano', column='GHI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'no momento, tem-se {len(csv)/5_785_920*100:.4}% dos dados iniciais')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv\n",
    "csv.boxplot(by='ano', column='Tracker off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.drop(csv[csv['Tracker off'] > 1].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv\n",
    "csv.boxplot(by='ano', column='Tracker off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv['Suspeito'] = (csv['Tracker off'] > 0.85)\n",
    "csv['Suspeito'].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
